# åŒ¯å…¥æ‰€éœ€å¥—ä»¶
import streamlit as st
import pandas as pd
import feedparser
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch
from statsmodels.tsa.statespace.sarimax import SARIMAX
import plotly.graph_objects as go
from FinMind.data import DataLoader
import datetime
import matplotlib.pyplot as plt

# è¨­å®š matplotlib å­—é«”ç‚ºå¾®è»Ÿæ­£é»‘é«”ï¼Œä»¥é¿å…ä¸­æ–‡äº‚ç¢¼
plt.rcParams['font.family'] = 'Microsoft JhengHei'

# è¼‰å…¥ FinBERT æ¨¡å‹
@st.cache_resource
def load_finbert():
    tokenizer = AutoTokenizer.from_pretrained("yiyanghkust/finbert-tone")
    model = AutoModelForSequenceClassification.from_pretrained("yiyanghkust/finbert-tone")
    return tokenizer, model

# è¼‰å…¥ HuggingFace ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹
@st.cache_resource
def load_chinese_sentiment():
    return pipeline("sentiment-analysis", model="uer/roberta-base-finetuned-jd-binary-chinese")

# å–å¾—è‹±æ–‡ RSS æ–°è
def fetch_rss_news_en():
    rss_url = "https://news.google.com/rss/search?q=TSMC&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(rss_url)
    return [entry.title for entry in feed.entries if entry.title.strip()]

# å–å¾—ä¸­æ–‡ RSS æ–°è
def fetch_rss_news_zh():
    rss_url = "https://news.google.com/rss/search?q=å°ç©é›»&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    feed = feedparser.parse(rss_url)
    return [entry.title for entry in feed.entries if entry.title.strip()]

# è‹±æ–‡æ–°èæƒ…æ„Ÿåˆ†æ
def finbert_sentiment(texts):
    tokenizer, model = load_finbert()
    sentiments = []
    valid_texts = []
    for text in texts:
        try:
            inputs = tokenizer(text, return_tensors="pt", truncation=True)
            with torch.no_grad():
                outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0].cpu().numpy()
            raw_score = probs[2] - probs[0]  # æ­£å‘æ©Ÿç‡ - è² å‘æ©Ÿç‡
            sentiments.append(float(raw_score))
            valid_texts.append(text)
        except:
            continue
    return valid_texts, sentiments

# ä¸­æ–‡æ–°èæƒ…æ„Ÿåˆ†æ
def chinese_sentiment(texts):
    classifier = load_chinese_sentiment()
    sentiments = []
    valid_texts = []
    for text in texts:
        try:
            result = classifier(text[:512])[0]
            score = result['score'] if result['label'] == 'positive' else -result['score']
            sentiments.append(score)
            valid_texts.append(text)
        except:
            continue
    return valid_texts, sentiments

# æº–å‚™è‚¡åƒ¹è³‡æ–™ï¼Œä¸¦åœ¨æœ€æ–°ä¸€å¤©åŠ å…¥æƒ…æ„Ÿåˆ†æ•¸ä½œç‚ºå¤–ç”Ÿè®Šæ•¸
def prepare_data(sentiment_score):
    today = datetime.date.today()
    start_date = today - datetime.timedelta(days=30)
    dl = DataLoader()
    try:
        data = dl.taiwan_stock_daily(stock_id="2330", start_date=str(start_date), end_date=str(today))
        if data.empty:
            st.error("âš  ç„¡æ³•å¾ FinMind å–å¾—è‚¡åƒ¹è³‡æ–™")
            return pd.DataFrame()

        df = data[['date', 'close']].rename(columns={'date': 'date', 'close': 'price'})
        df['date'] = pd.to_datetime(df['date'])
        df = df.tail(15).reset_index(drop=True)  # å–è¿‘15å¤©
        df['score'] = 0.0
        df.at[df.index[-1], 'score'] = float(sentiment_score)  # å°‡æƒ…æ„Ÿåˆ†æ•¸æ”¾åœ¨æœ€æ–°ä¸€å¤©
        return df
    except Exception as e:
        st.error(f"âš  è®€å– FinMind è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return pd.DataFrame()

# åˆ©ç”¨ SARIMAX æ¨¡å‹é€²è¡Œé æ¸¬ï¼Œä½¿ç”¨æƒ…æ„Ÿåˆ†æ•¸ä½œç‚ºå¤–ç”Ÿè®Šæ•¸
def forecast_arimax(df):
    df = df.dropna(subset=['price', 'score'])
    model = SARIMAX(df['price'], exog=df[['score']], order=(5,1,0))
    model_fit = model.fit(disp=False)
    future_sentiment = [[df['score'].iloc[-1]]] * 3  # é æ¸¬æœªä¾†3å¤©ï¼Œå¤–ç”Ÿè®Šæ•¸åŒå€¼
    forecast = model_fit.forecast(steps=3, exog=future_sentiment)
    return forecast

# æ ¹æ“šæƒ…æ„Ÿå¹³å‡å€¼èˆ‡è¿‘5æ—¥è‚¡åƒ¹è®ŠåŒ–çµ¦å‡ºæŠ•è³‡å»ºè­°
def investment_advice(avg_sentiment, price_series):
    if len(price_series) < 5:
        return "è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•æä¾›æŠ•è³‡å»ºè­°"
    recent_change = (price_series.iloc[-1] - price_series.iloc[-5]) / price_series.iloc[-5]
    if avg_sentiment > 0.05 and recent_change > 0:
        return "ğŸ’¡ AI æŠ•è³‡å»ºè­°ï¼šæƒ…æ„Ÿæ­£å‘ä¸”è‚¡åƒ¹ä¸Šå‡ï¼Œå»ºè­°è²·å…¥"
    elif avg_sentiment > 0.05 and recent_change <= 0:
        return "ğŸ’¡ AI æŠ•è³‡å»ºè­°ï¼šæƒ…æ„Ÿæ­£å‘ä½†è‚¡åƒ¹ä¸‹è·Œï¼Œå»ºè­°è§€å¯Ÿå¾Œå†æ±ºå®š"
    elif avg_sentiment < -0.05 and recent_change < 0:
        return "ğŸ’¡ AI æŠ•è³‡å»ºè­°ï¼šæƒ…æ„Ÿè² å‘ä¸”è‚¡åƒ¹ä¸‹è·Œï¼Œå»ºè­°è³£å‡º"
    elif avg_sentiment < -0.05 and recent_change >= 0:
        return "ğŸ’¡ AI æŠ•è³‡å»ºè­°ï¼šæƒ…æ„Ÿè² å‘ä½†è‚¡åƒ¹ä¸Šå‡ï¼Œå»ºè­°è¬¹æ…è§€å¯Ÿ"
    else:
        return "ğŸ’¡ AI æŠ•è³‡å»ºè­°ï¼šæƒ…æ„Ÿä¸­ç«‹ï¼Œå»ºè­°æŒçºŒè§€å¯Ÿ"

# ä¸»ç¨‹å¼å…¥å£
def main():
    st.title("ğŸ“ˆ é€éé›™èªæ–°èæƒ…æ„Ÿåˆ†æé€²è¡Œå°ç©é›»è‚¡åƒ¹é æ¸¬")

    # æŠ“å–æ–°èèˆ‡é€²è¡Œæƒ…æ„Ÿåˆ†æ
    headlines_en = fetch_rss_news_en()
    headlines_en, sentiments_en = finbert_sentiment(headlines_en)

    headlines_zh = fetch_rss_news_zh()
    headlines_zh, sentiments_zh = chinese_sentiment(headlines_zh)

    # ç¾åŒ–ï¼šæ»¾å‹•è¡¨æ ¼æ¨£å¼
    scroll_style = """
    <style>
    .scrollable-table {
        max-height: 300px;
        overflow-y: auto;
        border: 1px solid #ddd;
        padding: 10px;
        border-radius: 5px;
        background-color: #fafafa;
        margin-bottom: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ccc;
        padding: 6px;
        text-align: left;
        vertical-align: top;
    }
    </style>
    """
    st.markdown(scroll_style, unsafe_allow_html=True)

    # é¡¯ç¤ºè‹±æ–‡æ–°èèˆ‡åˆ†æçµæœ
    st.subheader("ğŸ“° è‹±æ–‡æ–°èèˆ‡æƒ…æ„Ÿåˆ†æ")
    if headlines_en:
        df_en = pd.DataFrame({"Headline": headlines_en, "Sentiment": sentiments_en})
        table_html = df_en.to_html(classes="scrollable-table", index=False)
        st.markdown(f'<div class="scrollable-table">{table_html}</div>', unsafe_allow_html=True)
        avg_sent_en = sum(sentiments_en) / len(sentiments_en)
        st.markdown(f"**Average Sentimentï¼š** {avg_sent_en:.4f}")
    else:
        st.warning("ç„¡æ³•å–å¾—è‹±æ–‡æ–°è")

    # é¡¯ç¤ºä¸­æ–‡æ–°èèˆ‡åˆ†æçµæœ
    st.subheader("ğŸ“° ä¸­æ–‡æ–°èèˆ‡æƒ…æ„Ÿåˆ†æ")
    if headlines_zh:
        df_zh = pd.DataFrame({"æ–°èæ¨™é¡Œ": headlines_zh, "æƒ…æ„Ÿåˆ†æ•¸": sentiments_zh})
        table_html = df_zh.to_html(classes="scrollable-table", index=False)
        st.markdown(f'<div class="scrollable-table">{table_html}</div>', unsafe_allow_html=True)
        avg_sent_zh = sum(sentiments_zh) / len(sentiments_zh)
        st.markdown(f"**å¹³å‡æƒ…æ„Ÿåˆ†æ•¸ï¼š** {avg_sent_zh:.4f}")
    else:
        st.warning("ç„¡æ³•å–å¾—ä¸­æ–‡æ–°è")

    # è¨ˆç®—ç¸½é«”å¹³å‡æƒ…æ„Ÿåˆ†æ•¸
    all_sentiments = sentiments_en + sentiments_zh
    avg_sentiment = sum(all_sentiments) / len(all_sentiments) if all_sentiments else 0

    # é¡¯ç¤ºè‚¡åƒ¹é æ¸¬
    show_forecast = st.checkbox("é¡¯ç¤ºè‚¡åƒ¹é æ¸¬")
    if show_forecast:
        st.subheader("ğŸ“Š å°ç©é›»è‚¡åƒ¹é æ¸¬")
        df_price = prepare_data(avg_sentiment)
        if df_price.empty:
            st.error("âš  ç„¡æ³•å–å¾—è‚¡åƒ¹è³‡æ–™")
            return

        # é æ¸¬æœªä¾†ä¸‰æ—¥
        pred = forecast_arimax(df_price)
        future_dates = pd.date_range(start=df_price['date'].iloc[-1] + pd.Timedelta(days=1), periods=10)
        future_dates = future_dates[future_dates.weekday < 5][:3]

        # ç¹ªè£½åœ–è¡¨
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=df_price['date'], y=df_price['price'],
                                mode='lines+markers', name='å¯¦éš›åƒ¹æ ¼'))
        fig.add_trace(go.Scatter(x=future_dates, y=pred,
                                mode='lines+markers', name='é æ¸¬åƒ¹æ ¼',
                                line=dict(dash='dash', color='red')))
        fig.update_layout(
            title="å°ç©é›»è‚¡åƒ¹é æ¸¬ï¼ˆå«æ–°èæƒ…æ„Ÿï¼‰",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="è‚¡åƒ¹ (æ–°å°å¹£)",
            hovermode='x unified',
            template='plotly_white',
            width=900,
            height=500,
        )
        st.plotly_chart(fig, use_container_width=True)

        # æŠ•è³‡å»ºè­°
        advice = investment_advice(avg_sentiment, df_price['price'])
        st.info(advice)

# ç¨‹å¼åŸ·è¡Œå…¥å£
if __name__ == "__main__":
    main()
